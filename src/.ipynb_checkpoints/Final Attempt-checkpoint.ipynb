{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd70d75-afc6-4621-b5a7-e29d6e65a352",
   "metadata": {},
   "source": [
    "# Performance Review\n",
    "Flawless, all code ran perfectly on first attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dcdfd0-89f3-4fa3-8139-030a91c7476e",
   "metadata": {},
   "source": [
    "# Code blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc9441-be15-410f-8c76-b86d96185110",
   "metadata": {},
   "source": [
    "## Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f91df2c-a5a5-4566-98c3-cb60b6c231db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8b5eb-f031-4e97-b04d-92adb93ac37f",
   "metadata": {},
   "source": [
    "## Create non-linear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fceddf48-3126-448a-992a-02ed05877fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "# if deriv = True, x must be output of a sigmoid function to correctly return derivative\n",
    "def Sigmoid(x, deriv = False):\n",
    "    if(deriv):\n",
    "        return x * (1-x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4027c8f-df54-4624-8dbf-23d981843a80",
   "metadata": {},
   "source": [
    "## Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee60214-a972-435b-9b53-d5474f75a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row is one input, each column represents the weight into 1 neuron\n",
    "weights0 = 2 * np.random.rand(3,4) - 1 # 3 inputs into 4 different hidden neurons\n",
    "weights1 = 2 * np.random.rand(4,1) - 1 # 4 hiddent neurons as input into 1 output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3613e09-8129-48b3-9956-496a01914413",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88efd2bf-54cb-47cb-9447-a3c767ef6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row is one data point, each column is one neuron\n",
    "# Each value is the output of that neuron at that data point\n",
    "l0 = X\n",
    "l1 = Sigmoid(np.dot(l0, weights0)) \n",
    "l2 = Sigmoid(np.dot(l1, weights1)) # Probability of 1 estimates according to NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445efbc-7b5d-4216-aa15-ed5bff0fd62e",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51cc8821-63d9-49a0-84cf-dc459e950de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error = y - l2\n",
    "l2_delta = l2_error * Sigmoid(l2, deriv = True) # Error scaled inversely with confidence\n",
    "\n",
    "l1_error = np.dot(l2_delta, weights1.T) # Error contribution of l1 neurons into l2 scaled error\n",
    "l1_delta = l1_error * Sigmoid(l1, deriv = True) # Error scaled inversely with confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b948206-5e38-4bb3-bbb5-cf2016ae6a43",
   "metadata": {},
   "source": [
    "### Update Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafe8990-c543-4f0c-b1c1-f66cb01a1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 += np.dot(l1.T, l2_delta)\n",
    "weights0 += np.dot(l0.T, l1_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7b1e39-3a52-47fe-bd83-023f51c96574",
   "metadata": {},
   "source": [
    "# Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc85aa82-d3e6-46ed-aff1-eb00c55f7ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.4964100319027255\n",
      "Error: 0.008584525653247157\n",
      "Error: 0.005789459862507806\n",
      "Error: 0.004629176776769983\n",
      "Error: 0.003958765280273646\n",
      "Error: 0.0035101225678616736\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Sigmoid activation function\n",
    "# if deriv = True, x must be output of a sigmoid function to correctly return derivative\n",
    "def Sigmoid(x, deriv = False):\n",
    "    if(deriv):\n",
    "        return x * (1-x)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Each row is one input, each column represents the weight into 1 neuron\n",
    "weights0 = 2 * np.random.rand(3,4) - 1 # 3 inputs into 4 different hidden neurons\n",
    "weights1 = 2 * np.random.rand(4,1) - 1 # 4 hiddent neurons as input into 1 output neuron\n",
    "\n",
    "for j in range(60000):\n",
    "    # Each row is one data point, each column is one neuron\n",
    "    # Each value is the output of that neuron at that data point\n",
    "    l0 = X\n",
    "    l1 = Sigmoid(np.dot(l0, weights0)) \n",
    "    l2 = Sigmoid(np.dot(l1, weights1)) # Probability of 1 estimates according to NN\n",
    "    \n",
    "    l2_error = y - l2\n",
    "    if (j % 10000) == 0:\n",
    "        print(\"Error: \" + str(np.mean(np.abs(l2_error))))\n",
    "    l2_delta = l2_error * Sigmoid(l2, deriv = True) # Error scaled inversely with confidence\n",
    "    \n",
    "    l1_error = np.dot(l2_delta, weights1.T) # Error contribution of l1 neurons into l2 scaled error\n",
    "    l1_delta = l1_error * Sigmoid(l1, deriv = True) # Error scaled inversely with confidence\n",
    "    \n",
    "    weights1 += np.dot(l1.T, l2_delta)\n",
    "    weights0 += np.dot(l0.T, l1_delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
