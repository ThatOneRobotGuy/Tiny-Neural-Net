{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255032da-3f35-4e19-86ec-88e6320cc43b",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88c1ec-897d-4a46-acd7-f9208280f5bb",
   "metadata": {},
   "source": [
    "**I had to check to:**\n",
    "* Make sure I had the update step formula correct (I did but at that point had forgotten why)\n",
    "* In the l1_error step, I had np.dot(l2_delta.T, weights1) instead of np.dot(l2_delta, weights1.T) (idk why since my understanding of what the format of the matrix was correct)\n",
    "\n",
    "Overall improvement over first attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20778c1-45b8-4026-a0c9-c928f5ef0fb8",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56d0cd1d-d5f8-4c84-947d-41f6ade6f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178abcc-f2c0-40e6-a824-c9b29b526f2f",
   "metadata": {},
   "source": [
    "## Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f114a558-c766-467e-a6e5-ea178a52bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights0 = 2 * np.random.rand(3,4) - 1 # 3 inputs into 4 hidden neurons\n",
    "weights1 = 2 * np.random.rand(4,1) - 1 # 4 hidden neurons into 1 output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1250be-294b-48c2-9ada-0920b145db2a",
   "metadata": {},
   "source": [
    "## Define activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9c86b5-649b-48fd-be3f-5eb5d6d73a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For deriv=True, x must be the output of a sigmoid function \n",
    "def sigmoid(x, deriv = False):\n",
    "    if(deriv):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14e374-9825-4a0c-af5a-bb94a2fc587d",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f33dc74-e32c-47f5-89e0-ef7200ff1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = X\n",
    "l1 = sigmoid(np.dot(l0, weights0)) # Each row represents one data point, each column 1 neuron output\n",
    "l2 = sigmoid(np.dot(l1, weights1)) # Same format as l1 but represents probability of 1 as determined by NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e6859-1461-45c3-9236-7165191e46c6",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "521a7a0e-46a8-4f9e-9ab6-264f353e6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_error = y - l2 # Error of NN\n",
    "l2_delta = l2_error * sigmoid(l2, deriv = True) # L2 error scaled inversely with confidence\n",
    "\n",
    "# Error contribution for l1 neurons\n",
    "# Each row represents one data point\n",
    "# Each column represents the error contribution of one l1 neuron\n",
    "l1_error = np.dot(l2_delta, weights1.T)  \n",
    "l1_delta = l1_error * sigmoid(l1, deriv = True)\n",
    "\n",
    "weights1 += np.dot(l1.T, l2_delta) # Change by sum of (input * scaled-error)\n",
    "weights0 += np.dot(l0.T, l2_delta) # Change by sum of (input * scaled-error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d75a9d0-1099-484a-93bd-1576e3009cbe",
   "metadata": {},
   "source": [
    "# Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23f16e1-ac34-41f1-a33e-76d63444c048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4964100319027255\n",
      "0.011633855795037226\n",
      "0.007726214608089648\n",
      "0.006140275631766903\n",
      "0.005232879516571011\n",
      "0.004629176776769983\n",
      "0.004191411997822936\n",
      "0.003855721334504095\n",
      "0.003587987771726254\n",
      "0.0033681382633601407\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "weights0 = 2 * np.random.rand(3,4) - 1 # 3 inputs into 4 hidden neurons\n",
    "weights1 = 2 * np.random.rand(4,1) - 1 # 4 hidden neurons into 1 output neuron\n",
    "\n",
    "# For deriv=True, x must be the output of a sigmoid function \n",
    "def sigmoid(x, deriv = False):\n",
    "    if(deriv):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "for j in range(60000):\n",
    "    l0 = X\n",
    "    l1 = sigmoid(np.dot(l0, weights0)) # Each row represents one data point, each column 1 neuron output\n",
    "    l2 = sigmoid(np.dot(l1, weights1)) # Same format as l1 but represents probability of 1 as determined by NN\n",
    "    \n",
    "    l2_error = y - l2 # Error of NN\n",
    "    l2_delta = l2_error * sigmoid(l2, deriv = True) # L2 error scaled inversely with confidence\n",
    "\n",
    "    # Error contribution for l1 neurons\n",
    "    # Each row represents one data point\n",
    "    # Each column represents the error contribution of one l1 neuron\n",
    "    l1_error = np.dot(l2_delta, weights1.T)  \n",
    "    l1_delta = l1_error * sigmoid(l1, deriv = True)\n",
    "\n",
    "    weights1 += np.dot(l1.T, l2_delta) # Change by sum of (input * scaled-error)\n",
    "    weights0 += np.dot(l0.T, l1_delta) # Change by sum of (input * scaled-error)\n",
    "\n",
    "    if (j % 6000 == 0):\n",
    "        print(np.mean(np.abs(l2_error)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb3945-e106-4273-b5dd-0b4d7c35ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
